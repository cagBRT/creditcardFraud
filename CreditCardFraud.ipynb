{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CreditCardFraud.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyP+4Ck/AQ5q2wxE10kH1FeG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/creditcardFraud/blob/main/CreditCardFraud.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-aMCyYw8mae"
      },
      "source": [
        "https://www.geeksforgeeks.org/ml-credit-card-fraud-detection/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDXZOpmZ05GA"
      },
      "source": [
        "# import the necessary packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib import gridspec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jj6HVH3008NX"
      },
      "source": [
        "df = pd.read_csv(\"creditcard.csv\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "731RSwMx4UKl"
      },
      "source": [
        "# Print the shape of the data\n",
        "# data = data.sample(frac = 0.1, random_state = 48)\n",
        "print(df.shape)\n",
        "print(df.describe())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JPp7XgE4lwt"
      },
      "source": [
        "# Determine number of fraud cases in dataset\n",
        "fraud = df[df['Class'] == 1]\n",
        "valid = df[df['Class'] == 0]\n",
        "outlierFraction = len(fraud)/float(len(valid))\n",
        "print(outlierFraction)\n",
        "print('Fraud Cases: {}'.format(len(df[df['Class'] == 1])))\n",
        "print('Valid Transactions: {}'.format(len(df[df['Class'] == 0])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5cxU6z1420a"
      },
      "source": [
        "print('Amount details of the fraudulent transaction')\n",
        "fraud.Amount.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMV12cWf5Yu7"
      },
      "source": [
        "print('details of valid transaction')\n",
        "valid.Amount.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geNKe_4S5dvM"
      },
      "source": [
        "# Correlation matrix\n",
        "corrmat = df.corr()\n",
        "fig = plt.figure(figsize = (12, 9))\n",
        "sns.heatmap(corrmat, vmax = .8, square = True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJNbIe4L5j1S"
      },
      "source": [
        "# dividing the X and the Y from the dataset\n",
        "X = df.drop(['Class'], axis = 1)\n",
        "Y = df[\"Class\"]\n",
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "# getting just the values for the sake of processing \n",
        "# (its a numpy array with no columns)\n",
        "xData = X.values\n",
        "yData = Y.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SCTxkqo5qeU"
      },
      "source": [
        "# Using Skicit-learn to split data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Split the data into training and testing sets\n",
        "xTrain, xTest, yTrain, yTest = train_test_split(\n",
        "        xData, yData, test_size = 0.2, random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cD019wug5uFY"
      },
      "source": [
        "# Building the Random Forest Classifier (RANDOM FOREST)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# random forest model creation\n",
        "rfc = RandomForestClassifier()\n",
        "rfc.fit(xTrain, yTrain)\n",
        "# predictions\n",
        "yPred = rfc.predict(xTest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVZva1rf5zWc"
      },
      "source": [
        "# Evaluating the classifier\n",
        "# printing every score of the classifier\n",
        "# scoring in anything\n",
        "from sklearn.metrics import classification_report, accuracy_score \n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from sklearn.metrics import f1_score, matthews_corrcoef\n",
        "from sklearn.metrics import confusion_matrix\n",
        "  \n",
        "n_outliers = len(fraud)\n",
        "n_errors = (yPred != yTest).sum()\n",
        "print(\"The model used is Random Forest classifier\")\n",
        "  \n",
        "acc = accuracy_score(yTest, yPred)\n",
        "print(\"The accuracy is {}\".format(acc))\n",
        "  \n",
        "prec = precision_score(yTest, yPred)\n",
        "print(\"The precision is {}\".format(prec))\n",
        "  \n",
        "rec = recall_score(yTest, yPred)\n",
        "print(\"The recall is {}\".format(rec))\n",
        "  \n",
        "f1 = f1_score(yTest, yPred)\n",
        "print(\"The F1-Score is {}\".format(f1))\n",
        "  \n",
        "MCC = matthews_corrcoef(yTest, yPred)\n",
        "print(\"The Matthews correlation coefficient is{}\".format(MCC))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCKdjbzU8dbQ"
      },
      "source": [
        "# printing the confusion matrix\n",
        "LABELS = ['Normal', 'Fraud']\n",
        "conf_matrix = confusion_matrix(yTest, yPred)\n",
        "plt.figure(figsize =(12, 12))\n",
        "sns.heatmap(conf_matrix, xticklabels = LABELS, \n",
        "            yticklabels = LABELS, annot = True, fmt =\"d\");\n",
        "plt.title(\"Confusion matrix\")\n",
        "plt.ylabel('True class')\n",
        "plt.xlabel('Predicted class')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}